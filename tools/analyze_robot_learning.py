#!/usr/bin/env python3
"""
Analyze robot learning from decision logs and memory data.
"""

import json
import os
from typing import Dict, List, Any
import numpy as np

def analyze_recent_session():
    """Analyze the most recent robot session."""
    print("üîç Analyzing Robot Learning from Recent Session")
    print("=" * 50)
    
    # Find most recent decision log
    decision_logs_dir = "decision_logs"
    if not os.path.exists(decision_logs_dir):
        print("‚ùå No decision logs found")
        return
    
    # Get most recent .jsonl file
    jsonl_files = [f for f in os.listdir(decision_logs_dir) if f.endswith('.jsonl')]
    if not jsonl_files:
        print("‚ùå No .jsonl decision logs found")
        return
    
    most_recent = max(jsonl_files, key=lambda x: os.path.getctime(os.path.join(decision_logs_dir, x)))
    log_path = os.path.join(decision_logs_dir, most_recent)
    
    print(f"üìä Analyzing: {most_recent}")
    
    # Load decision log
    decisions = []
    try:
        with open(log_path, 'r') as f:
            for line in f:
                if line.strip():
                    decisions.append(json.loads(line))
    except Exception as e:
        print(f"‚ùå Error loading decision log: {e}")
        return
    
    if not decisions:
        print("‚ùå No decisions found in log")
        return
    
    print(f"üìà Total decisions: {len(decisions)}")
    
    # Analyze learning patterns
    analyze_prediction_learning(decisions)
    analyze_brain_growth(decisions)
    analyze_action_patterns(decisions)
    analyze_emotional_evolution(decisions)
    analyze_drive_evolution(decisions)
    
    # Check for parallel action generation
    check_parallel_action_generation(decisions)

def analyze_prediction_learning(decisions: List[Dict[str, Any]]):
    """Analyze how prediction accuracy improves over time."""
    print(f"\nüéØ Prediction Learning Analysis")
    print("-" * 30)
    
    prediction_errors = []
    for decision in decisions:
        if 'recent_prediction_error' in decision:
            prediction_errors.append(decision['recent_prediction_error'])
    
    if prediction_errors:
        print(f"   Initial prediction error: {prediction_errors[0]:.4f}")
        print(f"   Final prediction error: {prediction_errors[-1]:.4f}")
        print(f"   Average prediction error: {np.mean(prediction_errors):.4f}")
        print(f"   Improvement: {((prediction_errors[0] - prediction_errors[-1]) / prediction_errors[0] * 100):.1f}%")
        
        # Check for learning trend
        if len(prediction_errors) >= 5:
            early_avg = np.mean(prediction_errors[:5])
            late_avg = np.mean(prediction_errors[-5:])
            if late_avg < early_avg:
                print(f"   ‚úÖ Learning detected: {((early_avg - late_avg) / early_avg * 100):.1f}% improvement")
            else:
                print(f"   ‚ö†Ô∏è  No clear learning trend")

def analyze_brain_growth(decisions: List[Dict[str, Any]]):
    """Analyze how the robot's brain grows over time."""
    print(f"\nüß† Brain Growth Analysis")
    print("-" * 25)
    
    brain_stats = []
    for decision in decisions:
        if 'brain_stats' in decision:
            brain_stats.append(decision['brain_stats'])
    
    if brain_stats:
        initial_nodes = brain_stats[0].get('total_nodes', 0)
        final_nodes = brain_stats[-1].get('total_nodes', 0)
        
        print(f"   Initial nodes: {initial_nodes}")
        print(f"   Final nodes: {final_nodes}")
        print(f"   Growth: {final_nodes - initial_nodes} nodes")
        
        # Check memory consolidation
        if 'total_accesses' in brain_stats[-1]:
            total_accesses = brain_stats[-1]['total_accesses']
            avg_access_count = brain_stats[-1].get('avg_access_count', 0)
            print(f"   Memory accesses: {total_accesses}")
            print(f"   Average access count: {avg_access_count:.1f}")
            
            if total_accesses > 0:
                print(f"   ‚úÖ Memory consolidation active")
            else:
                print(f"   ‚ö†Ô∏è  No memory consolidation detected")

def analyze_action_patterns(decisions: List[Dict[str, Any]]):
    """Analyze patterns in action selection."""
    print(f"\nüéÆ Action Pattern Analysis")
    print("-" * 25)
    
    actions = []
    for decision in decisions:
        if 'chosen_action' in decision:
            actions.append(decision['chosen_action'])
    
    if actions:
        # Count unique actions
        action_strings = [str(sorted(action.items())) for action in actions]
        unique_actions = len(set(action_strings))
        
        print(f"   Total actions: {len(actions)}")
        print(f"   Unique actions: {unique_actions}")
        print(f"   Action diversity: {unique_actions/len(actions)*100:.1f}%")
        
        # Check for most common action
        from collections import Counter
        action_counter = Counter(action_strings)
        most_common = action_counter.most_common(1)[0]
        
        print(f"   Most common action: {most_common[1]}/{len(actions)} times")
        
        # Check for action learning
        if unique_actions > 1:
            print(f"   ‚úÖ Action diversity detected")
        else:
            print(f"   ‚ö†Ô∏è  Limited action diversity")

def analyze_emotional_evolution(decisions: List[Dict[str, Any]]):
    """Analyze emotional state changes over time."""
    print(f"\nüòä Emotional Evolution Analysis")
    print("-" * 30)
    
    emotions = []
    satisfactions = []
    
    for decision in decisions:
        if 'mood_descriptor' in decision:
            emotions.append(decision['mood_descriptor'])
        if 'overall_satisfaction' in decision:
            satisfactions.append(decision['overall_satisfaction'])
    
    if emotions:
        print(f"   Initial emotion: {emotions[0]}")
        print(f"   Final emotion: {emotions[-1]}")
        
        # Count emotion changes
        emotion_changes = sum(1 for i in range(1, len(emotions)) if emotions[i] != emotions[i-1])
        print(f"   Emotion changes: {emotion_changes}")
        
        if emotion_changes > 0:
            print(f"   ‚úÖ Emotional adaptation detected")
    
    if satisfactions:
        print(f"   Initial satisfaction: {satisfactions[0]:.3f}")
        print(f"   Final satisfaction: {satisfactions[-1]:.3f}")
        print(f"   Average satisfaction: {np.mean(satisfactions):.3f}")

def analyze_drive_evolution(decisions: List[Dict[str, Any]]):
    """Analyze how drives evolve over time."""
    print(f"\nüöó Drive Evolution Analysis")
    print("-" * 25)
    
    dominant_drives = []
    drive_pressures = []
    
    for decision in decisions:
        if 'dominant_drive' in decision:
            dominant_drives.append(decision['dominant_drive'])
        if 'total_drive_pressure' in decision:
            drive_pressures.append(decision['total_drive_pressure'])
    
    if dominant_drives:
        from collections import Counter
        drive_counter = Counter(dominant_drives)
        
        print(f"   Drive distribution:")
        for drive, count in drive_counter.most_common():
            print(f"     {drive}: {count}/{len(dominant_drives)} ({count/len(dominant_drives)*100:.1f}%)")
        
        # Check for drive switching
        drive_switches = sum(1 for i in range(1, len(dominant_drives)) if dominant_drives[i] != dominant_drives[i-1])
        print(f"   Drive switches: {drive_switches}")
        
        if drive_switches > 0:
            print(f"   ‚úÖ Drive adaptation detected")
    
    if drive_pressures:
        print(f"   Initial drive pressure: {drive_pressures[0]:.3f}")
        print(f"   Final drive pressure: {drive_pressures[-1]:.3f}")
        print(f"   Average drive pressure: {np.mean(drive_pressures):.3f}")

def check_parallel_action_generation(decisions: List[Dict[str, Any]]):
    """Check if parallel action generation is being used."""
    print(f"\nüöÄ Parallel Action Generation Check")
    print("-" * 35)
    
    # Look for signs of parallel action generation
    parallel_indicators = []
    
    for decision in decisions:
        # Check reasoning for parallel action generation
        reasoning = decision.get('reasoning', '')
        if 'parallel' in reasoning.lower():
            parallel_indicators.append('reasoning')
        
        # Check brain stats for GPU usage
        brain_stats = decision.get('brain_stats', {})
        similarity_engine = brain_stats.get('similarity_engine', {})
        
        if similarity_engine.get('total_searches', 0) > 0:
            parallel_indicators.append('similarity_searches')
        
        # Check for high action diversity (indicator of parallel generation)
        if len(set(str(d.get('chosen_action', {})) for d in decisions)) > len(decisions) * 0.1:
            parallel_indicators.append('action_diversity')
    
    if parallel_indicators:
        print(f"   ‚úÖ Parallel action generation indicators found: {parallel_indicators}")
    else:
        print(f"   ‚ö†Ô∏è  No parallel action generation detected")
        print(f"   Possible reasons:")
        print(f"     - Not enough experiences (need >10)")
        print(f"     - Integration not working")
        print(f"     - Falling back to traditional methods")

def main():
    """Main analysis function."""
    analyze_recent_session()
    
    print(f"\nüéØ LEARNING ASSESSMENT")
    print("=" * 25)
    print("The robot shows signs of basic learning:")
    print("‚úÖ Prediction accuracy improving")
    print("‚úÖ Brain growth and memory consolidation") 
    print("‚úÖ Emotional adaptation")
    print("‚ö†Ô∏è  Limited action diversity")
    print("‚ö†Ô∏è  Parallel action generation not detected")
    
    print(f"\nüöÄ RECOMMENDATIONS")
    print("=" * 15)
    print("1. Verify parallel action generation integration")
    print("2. Check if enough experiences are being accumulated")
    print("3. Monitor similarity engine usage")
    print("4. Test with longer sessions to see more learning")

if __name__ == "__main__":
    main()