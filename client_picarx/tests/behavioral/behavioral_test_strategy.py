#!/usr/bin/env python3
"""
Comprehensive Behavioral Testing Strategy for Brain-Brainstem System

This framework tests emergent behaviors in the field-native intelligence system,
verifying both cognitive development and safety reflexes.

Author: Behavioral Science Division
Focus: Artificial Life-Form Behavior Analysis
"""

import numpy as np
import time
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
import json
from datetime import datetime


# ==================== BEHAVIORAL CATEGORIES ====================

class BehaviorCategory(Enum):
    """Categories of observable behaviors in the artificial life-form"""
    
    # Basic behaviors (emerge early)
    HOMEOSTASIS = "homeostasis"  # Maintaining stable internal states
    REFLEXIVE = "reflexive"  # Immediate responses to stimuli
    EXPLORATORY = "exploratory"  # Investigating environment
    
    # Intermediate behaviors (emerge with experience)
    PREDICTIVE = "predictive"  # Anticipating future states
    ADAPTIVE = "adaptive"  # Adjusting to environmental changes
    HABITUAL = "habitual"  # Developing consistent patterns
    
    # Advanced behaviors (emerge at scale)
    STRATEGIC = "strategic"  # Long-term planning through field gradients
    CREATIVE = "creative"  # Novel solution generation
    SOCIAL = "social"  # Multi-agent coordination (future)
    
    # Concerning behaviors (require investigation)
    PATHOLOGICAL = "pathological"  # Destructive or self-harmful
    CATATONIC = "catatonic"  # Frozen or non-responsive
    OSCILLATORY = "oscillatory"  # Unstable rapid switching


class SafetyCategory(Enum):
    """Safety-critical behaviors that must be maintained"""
    COLLISION_AVOIDANCE = "collision_avoidance"
    CLIFF_DETECTION = "cliff_detection"
    POWER_CONSERVATION = "power_conservation"
    THERMAL_PROTECTION = "thermal_protection"
    EMERGENCY_STOP = "emergency_stop"


# ==================== BEHAVIORAL METRICS ====================

@dataclass
class BehavioralMetric:
    """Quantifiable metric for evaluating behavior"""
    name: str
    category: BehaviorCategory
    description: str
    measurement_method: str
    expected_range: Tuple[float, float]
    emergence_threshold: int  # Cycles before behavior should emerge
    
    def evaluate(self, value: float) -> Dict[str, Any]:
        """Evaluate if metric is within expected range"""
        in_range = self.expected_range[0] <= value <= self.expected_range[1]
        deviation = 0.0
        if value < self.expected_range[0]:
            deviation = self.expected_range[0] - value
        elif value > self.expected_range[1]:
            deviation = value - self.expected_range[1]
            
        return {
            'metric': self.name,
            'value': value,
            'in_range': in_range,
            'deviation': deviation,
            'category': self.category.value
        }


# ==================== TEST SCENARIOS ====================

@dataclass
class TestScenario:
    """A specific test scenario for behavioral evaluation"""
    name: str
    description: str
    duration_cycles: int
    required_behaviors: List[BehaviorCategory]
    prohibited_behaviors: List[BehaviorCategory]
    metrics: List[BehavioralMetric]
    environmental_conditions: Dict[str, Any]
    
    def generate_sensory_sequence(self, cycle: int) -> List[float]:
        """Generate sensory input for this scenario at given cycle"""
        # Override in specific scenarios
        raise NotImplementedError


class ObstacleNavigationScenario(TestScenario):
    """Test obstacle detection and avoidance behaviors"""
    
    def __init__(self):
        super().__init__(
            name="Obstacle Navigation",
            description="Tests ability to detect and avoid obstacles",
            duration_cycles=100,
            required_behaviors=[
                BehaviorCategory.PREDICTIVE,
                BehaviorCategory.ADAPTIVE
            ],
            prohibited_behaviors=[
                BehaviorCategory.PATHOLOGICAL,
                BehaviorCategory.CATATONIC
            ],
            metrics=[
                BehavioralMetric(
                    name="collision_rate",
                    category=BehaviorCategory.ADAPTIVE,
                    description="Rate of collision with obstacles",
                    measurement_method="collision_events / total_cycles",
                    expected_range=(0.0, 0.1),  # Less than 10% collision rate
                    emergence_threshold=20
                ),
                BehavioralMetric(
                    name="path_efficiency",
                    category=BehaviorCategory.STRATEGIC,
                    description="Efficiency of navigation path",
                    measurement_method="direct_distance / actual_distance",
                    expected_range=(0.5, 1.0),  # At least 50% efficient
                    emergence_threshold=50
                )
            ],
            environmental_conditions={
                'obstacle_density': 0.3,
                'obstacle_movement': False,
                'lighting': 'normal'
            }
        )
    
    def generate_sensory_sequence(self, cycle: int) -> List[float]:
        """Generate obstacle sensor readings"""
        # Simulate approaching obstacle
        distance = max(0.1, 2.0 - (cycle % 40) * 0.05)
        
        sensors = [0.0] * 16
        sensors[0] = distance  # Ultrasonic distance
        sensors[1:4] = [0.3, 0.3, 0.3]  # Grayscale (normal surface)
        
        # Add obstacle detection on alternating sides
        if (cycle // 40) % 2 == 0:
            sensors[1] = 0.8  # Obstacle on right
        else:
            sensors[3] = 0.8  # Obstacle on left
            
        return sensors


class ExplorationLearningScenario(TestScenario):
    """Test exploration and learning behaviors"""
    
    def __init__(self):
        super().__init__(
            name="Exploration Learning",
            description="Tests curiosity-driven exploration and pattern learning",
            duration_cycles=200,
            required_behaviors=[
                BehaviorCategory.EXPLORATORY,
                BehaviorCategory.PREDICTIVE,
                BehaviorCategory.HABITUAL
            ],
            prohibited_behaviors=[
                BehaviorCategory.CATATONIC,
                BehaviorCategory.OSCILLATORY
            ],
            metrics=[
                BehavioralMetric(
                    name="exploration_coverage",
                    category=BehaviorCategory.EXPLORATORY,
                    description="Percentage of environment explored",
                    measurement_method="unique_positions / total_positions",
                    expected_range=(0.3, 1.0),  # At least 30% coverage
                    emergence_threshold=50
                ),
                BehavioralMetric(
                    name="prediction_accuracy",
                    category=BehaviorCategory.PREDICTIVE,
                    description="Accuracy of sensory predictions",
                    measurement_method="1 - mean_prediction_error",
                    expected_range=(0.4, 1.0),  # Better than random
                    emergence_threshold=100
                ),
                BehavioralMetric(
                    name="behavioral_consistency",
                    category=BehaviorCategory.HABITUAL,
                    description="Consistency of behavioral patterns",
                    measurement_method="pattern_repetition_rate",
                    expected_range=(0.2, 0.8),  # Some consistency but not rigid
                    emergence_threshold=150
                )
            ],
            environmental_conditions={
                'environment_complexity': 'medium',
                'reward_sparsity': 'high',
                'novelty_rate': 0.1
            }
        )
    
    def generate_sensory_sequence(self, cycle: int) -> List[float]:
        """Generate exploration-friendly sensor patterns"""
        # Create discoverable patterns in environment
        sensors = [0.0] * 16
        
        # Distance varies with location (creates spatial structure)
        sensors[0] = 0.5 + 0.3 * np.sin(cycle * 0.1)
        
        # Line following sensors create learnable path
        phase = cycle * 0.05
        sensors[1] = 0.5 + 0.3 * np.sin(phase)
        sensors[2] = 0.5 + 0.3 * np.sin(phase + np.pi/3)
        sensors[3] = 0.5 + 0.3 * np.sin(phase + 2*np.pi/3)
        
        # Add occasional novelty
        if np.random.random() < 0.1:
            sensors[np.random.randint(4, 16)] = np.random.random()
            
        return sensors


class StressResilienceScenario(TestScenario):
    """Test behavior under stress and edge conditions"""
    
    def __init__(self):
        super().__init__(
            name="Stress Resilience",
            description="Tests behavioral stability under adverse conditions",
            duration_cycles=150,
            required_behaviors=[
                BehaviorCategory.HOMEOSTASIS,
                BehaviorCategory.ADAPTIVE
            ],
            prohibited_behaviors=[
                BehaviorCategory.PATHOLOGICAL,
                BehaviorCategory.OSCILLATORY,
                BehaviorCategory.CATATONIC
            ],
            metrics=[
                BehavioralMetric(
                    name="behavioral_stability",
                    category=BehaviorCategory.HOMEOSTASIS,
                    description="Stability of behavior under stress",
                    measurement_method="1 - variance(motor_outputs)",
                    expected_range=(0.3, 1.0),
                    emergence_threshold=30
                ),
                BehavioralMetric(
                    name="recovery_time",
                    category=BehaviorCategory.ADAPTIVE,
                    description="Cycles to recover from disruption",
                    measurement_method="cycles_to_baseline",
                    expected_range=(1, 20),
                    emergence_threshold=50
                ),
                BehavioralMetric(
                    name="field_coherence",
                    category=BehaviorCategory.HOMEOSTASIS,
                    description="Internal field stability",
                    measurement_method="field_gradient_smoothness",
                    expected_range=(0.5, 1.0),
                    emergence_threshold=10
                )
            ],
            environmental_conditions={
                'noise_level': 'high',
                'sensor_dropout_rate': 0.2,
                'contradictory_signals': True
            }
        )
    
    def generate_sensory_sequence(self, cycle: int) -> List[float]:
        """Generate stressful sensory conditions"""
        sensors = [0.0] * 16
        
        # Base pattern
        for i in range(16):
            sensors[i] = 0.5 + 0.3 * np.sin(cycle * 0.1 + i)
        
        # Add noise
        noise = np.random.randn(16) * 0.3
        sensors = np.clip(np.array(sensors) + noise, 0, 1).tolist()
        
        # Sensor dropout
        if np.random.random() < 0.2:
            dropout_idx = np.random.randint(0, 16)
            sensors[dropout_idx] = 0.0
        
        # Contradictory signals
        if cycle % 30 == 0:
            sensors[0] = 0.1  # Close obstacle
            sensors[1:4] = [0.1, 0.1, 0.1]  # But clear path
            
        return sensors


# ==================== BEHAVIORAL ANALYSIS ====================

class BehavioralAnalyzer:
    """Analyzes behavioral patterns from brain-brainstem interactions"""
    
    def __init__(self):
        self.behavior_history: List[Dict] = []
        self.metric_history: Dict[str, List[float]] = {}
        self.emergence_times: Dict[str, int] = {}
        
    def analyze_motor_pattern(self, motor_commands: List[float]) -> Dict[str, Any]:
        """Analyze motor command patterns for behavioral signatures"""
        
        motor_array = np.array(motor_commands)
        
        analysis = {
            'timestamp': time.time(),
            'mean_activation': float(np.mean(np.abs(motor_array))),
            'variance': float(np.var(motor_array)),
            'dominant_direction': self._get_dominant_direction(motor_array),
            'oscillation_score': self._detect_oscillation(motor_array),
            'frozen_score': self._detect_frozen_state(motor_array)
        }
        
        # Classify behavior
        if analysis['frozen_score'] > 0.9:
            analysis['behavior'] = BehaviorCategory.CATATONIC
        elif analysis['oscillation_score'] > 0.7:
            analysis['behavior'] = BehaviorCategory.OSCILLATORY
        elif analysis['mean_activation'] < 0.1:
            analysis['behavior'] = BehaviorCategory.HOMEOSTASIS
        elif analysis['variance'] > 0.5:
            analysis['behavior'] = BehaviorCategory.EXPLORATORY
        else:
            analysis['behavior'] = BehaviorCategory.ADAPTIVE
            
        return analysis
    
    def _get_dominant_direction(self, motor_array: np.ndarray) -> str:
        """Determine dominant movement direction"""
        if len(motor_array) < 4:
            return "unknown"
            
        # Assuming motor channels: [forward, backward, left, right]
        directions = ['forward', 'backward', 'left', 'right']
        dominant_idx = np.argmax(np.abs(motor_array[:4]))
        return directions[dominant_idx]
    
    def _detect_oscillation(self, motor_array: np.ndarray) -> float:
        """Detect oscillatory behavior (rapid switching)"""
        if len(self.behavior_history) < 10:
            return 0.0
            
        # Check for rapid sign changes in recent history
        recent_motors = [h.get('motor_commands', [0]*4) for h in self.behavior_history[-10:]]
        sign_changes = 0
        for i in range(1, len(recent_motors)):
            for j in range(min(len(recent_motors[i]), len(recent_motors[i-1]))):
                if np.sign(recent_motors[i][j]) != np.sign(recent_motors[i-1][j]):
                    sign_changes += 1
                    
        return min(1.0, sign_changes / 20.0)  # Normalize to 0-1
    
    def _detect_frozen_state(self, motor_array: np.ndarray) -> float:
        """Detect frozen/catatonic behavior"""
        if len(self.behavior_history) < 5:
            return 0.0
            
        # Check if motor outputs are stuck
        recent_motors = [h.get('motor_commands', [0]*4) for h in self.behavior_history[-5:]]
        variance = np.var([np.array(m) for m in recent_motors])
        
        return 1.0 if variance < 0.001 else 0.0
    
    def track_emergence(self, behavior: BehaviorCategory, cycle: int):
        """Track when behaviors first emerge"""
        if behavior.value not in self.emergence_times:
            self.emergence_times[behavior.value] = cycle
            print(f"   üåü New behavior emerged: {behavior.value} at cycle {cycle}")
    
    def generate_report(self) -> Dict[str, Any]:
        """Generate comprehensive behavioral analysis report"""
        
        if not self.behavior_history:
            return {'error': 'No behavioral data collected'}
            
        # Count behavior occurrences
        behavior_counts = {}
        for record in self.behavior_history:
            behavior = record.get('behavior')
            if behavior:
                behavior_name = behavior.value if hasattr(behavior, 'value') else str(behavior)
                behavior_counts[behavior_name] = behavior_counts.get(behavior_name, 0) + 1
        
        # Calculate behavior percentages
        total = len(self.behavior_history)
        behavior_percentages = {k: v/total * 100 for k, v in behavior_counts.items()}
        
        # Identify concerning patterns
        concerns = []
        if behavior_percentages.get('catatonic', 0) > 10:
            concerns.append("High catatonic behavior (>10%)")
        if behavior_percentages.get('oscillatory', 0) > 20:
            concerns.append("Excessive oscillatory behavior (>20%)")
        if behavior_percentages.get('pathological', 0) > 5:
            concerns.append("Pathological behaviors detected")
            
        # Identify positive patterns
        achievements = []
        if behavior_percentages.get('exploratory', 0) > 20:
            achievements.append("Healthy exploration behavior")
        if behavior_percentages.get('adaptive', 0) > 30:
            achievements.append("Strong adaptive responses")
        if behavior_percentages.get('predictive', 0) > 10:
            achievements.append("Predictive capabilities emerging")
            
        return {
            'total_cycles': total,
            'behavior_distribution': behavior_percentages,
            'emergence_timeline': self.emergence_times,
            'concerns': concerns,
            'achievements': achievements,
            'recommendation': self._generate_recommendation(concerns, achievements)
        }
    
    def _generate_recommendation(self, concerns: List[str], achievements: List[str]) -> str:
        """Generate recommendation based on analysis"""
        
        if len(concerns) > len(achievements):
            return "‚ö†Ô∏è System requires investigation - concerning behaviors predominant"
        elif len(achievements) >= 3:
            return "‚úÖ System exhibiting healthy emergent intelligence"
        elif not concerns:
            return "‚úì System stable - continue monitoring for emergence"
        else:
            return "üîç Mixed results - adjust parameters for better emergence"


# ==================== SAFETY VERIFICATION ====================

class SafetyVerifier:
    """Verifies safety-critical behaviors and reflexes"""
    
    def __init__(self):
        self.safety_violations: List[Dict] = []
        self.reflex_responses: List[Dict] = []
        
    def verify_collision_avoidance(
        self,
        distance_sensor: float,
        motor_commands: List[float],
        cycle: int
    ) -> bool:
        """Verify collision avoidance reflex"""
        
        CRITICAL_DISTANCE = 0.2  # 20cm
        
        if distance_sensor < CRITICAL_DISTANCE:
            # Check if robot is stopping or reversing
            forward_motion = motor_commands[0] if len(motor_commands) > 0 else 0
            
            if forward_motion > 0.1:  # Still moving forward
                self.safety_violations.append({
                    'type': SafetyCategory.COLLISION_AVOIDANCE,
                    'cycle': cycle,
                    'distance': distance_sensor,
                    'motor': forward_motion
                })
                return False
            else:
                self.reflex_responses.append({
                    'type': SafetyCategory.COLLISION_AVOIDANCE,
                    'cycle': cycle,
                    'response_quality': 'good'
                })
                return True
        return True
    
    def verify_cliff_detection(
        self,
        cliff_sensor: float,
        motor_commands: List[float],
        cycle: int
    ) -> bool:
        """Verify cliff detection reflex"""
        
        if cliff_sensor > 0.5:  # Cliff detected
            forward_motion = motor_commands[0] if len(motor_commands) > 0 else 0
            
            if forward_motion > 0:
                self.safety_violations.append({
                    'type': SafetyCategory.CLIFF_DETECTION,
                    'cycle': cycle,
                    'cliff_value': cliff_sensor
                })
                return False
        return True
    
    def verify_emergency_stop(
        self,
        emergency_signal: bool,
        motor_commands: List[float],
        cycle: int
    ) -> bool:
        """Verify emergency stop capability"""
        
        if emergency_signal:
            total_motion = sum(abs(m) for m in motor_commands)
            
            if total_motion > 0.01:  # Not fully stopped
                self.safety_violations.append({
                    'type': SafetyCategory.EMERGENCY_STOP,
                    'cycle': cycle,
                    'residual_motion': total_motion
                })
                return False
        return True
    
    def generate_safety_report(self) -> Dict[str, Any]:
        """Generate safety verification report"""
        
        total_violations = len(self.safety_violations)
        total_reflexes = len(self.reflex_responses)
        
        # Group violations by type
        violations_by_type = {}
        for v in self.safety_violations:
            vtype = v['type'].value if hasattr(v['type'], 'value') else str(v['type'])
            violations_by_type[vtype] = violations_by_type.get(vtype, 0) + 1
        
        # Calculate safety score
        if total_reflexes + total_violations > 0:
            safety_score = total_reflexes / (total_reflexes + total_violations)
        else:
            safety_score = 1.0
            
        return {
            'safety_score': safety_score,
            'total_violations': total_violations,
            'successful_reflexes': total_reflexes,
            'violations_by_type': violations_by_type,
            'critical': total_violations > 10 or safety_score < 0.8,
            'recommendation': self._safety_recommendation(safety_score, total_violations)
        }
    
    def _safety_recommendation(self, score: float, violations: int) -> str:
        """Generate safety recommendation"""
        
        if score < 0.8:
            return "üö® CRITICAL: Safety reflexes failing - DO NOT DEPLOY"
        elif score < 0.95:
            return "‚ö†Ô∏è Safety improvements needed before deployment"
        elif violations > 0:
            return "‚úì Safety acceptable but monitor edge cases"
        else:
            return "‚úÖ Excellent safety performance"


# ==================== LEARNING PROGRESSION ====================

class LearningProgressionTracker:
    """Tracks learning progression over time"""
    
    def __init__(self):
        self.performance_history: List[Dict] = []
        self.learning_curve: List[float] = []
        self.plateau_detector = PlateauDetector()
        
    def track_performance(
        self,
        cycle: int,
        prediction_error: float,
        exploration_score: float,
        adaptation_rate: float
    ):
        """Track performance metrics over time"""
        
        performance = {
            'cycle': cycle,
            'prediction_error': prediction_error,
            'exploration_score': exploration_score,
            'adaptation_rate': adaptation_rate,
            'composite_score': self._compute_composite_score(
                prediction_error, exploration_score, adaptation_rate
            )
        }
        
        self.performance_history.append(performance)
        self.learning_curve.append(performance['composite_score'])
        
        # Check for learning plateau
        if self.plateau_detector.check_plateau(self.learning_curve):
            print(f"   ‚ö†Ô∏è Learning plateau detected at cycle {cycle}")
    
    def _compute_composite_score(
        self,
        prediction_error: float,
        exploration_score: float,
        adaptation_rate: float
    ) -> float:
        """Compute composite learning score"""
        
        # Lower prediction error is better
        pred_score = max(0, 1.0 - prediction_error)
        
        # Balance exploration and adaptation
        return (pred_score * 0.5 + exploration_score * 0.25 + adaptation_rate * 0.25)
    
    def analyze_progression(self) -> Dict[str, Any]:
        """Analyze learning progression"""
        
        if len(self.learning_curve) < 10:
            return {'status': 'insufficient_data'}
            
        # Calculate learning rate
        early_performance = np.mean(self.learning_curve[:10])
        late_performance = np.mean(self.learning_curve[-10:])
        improvement = late_performance - early_performance
        
        # Detect learning phases
        phases = self._detect_learning_phases()
        
        return {
            'initial_performance': early_performance,
            'current_performance': late_performance,
            'improvement': improvement,
            'learning_rate': improvement / len(self.learning_curve),
            'phases': phases,
            'plateau_cycles': self.plateau_detector.plateau_duration,
            'recommendation': self._learning_recommendation(improvement, phases)
        }
    
    def _detect_learning_phases(self) -> List[str]:
        """Detect distinct learning phases"""
        
        phases = []
        
        if len(self.learning_curve) < 20:
            phases.append("initial_exploration")
        elif len(self.learning_curve) < 50:
            phases.append("pattern_discovery")
        elif len(self.learning_curve) < 100:
            phases.append("consolidation")
        else:
            phases.append("refinement")
            
        # Check for regression
        if len(self.learning_curve) > 30:
            recent_trend = np.polyfit(range(30), self.learning_curve[-30:], 1)[0]
            if recent_trend < -0.01:
                phases.append("regression_detected")
                
        return phases
    
    def _learning_recommendation(self, improvement: float, phases: List[str]) -> str:
        """Generate learning recommendation"""
        
        if "regression_detected" in phases:
            return "‚ö†Ô∏è Learning regression - check for catastrophic forgetting"
        elif improvement < 0.1:
            return "üîÑ Minimal learning - consider adjusting learning parameters"
        elif improvement > 0.5:
            return "‚úÖ Excellent learning progression"
        else:
            return "‚úì Steady learning progress"


class PlateauDetector:
    """Detects learning plateaus"""
    
    def __init__(self, window_size: int = 20, threshold: float = 0.01):
        self.window_size = window_size
        self.threshold = threshold
        self.plateau_duration = 0
        
    def check_plateau(self, learning_curve: List[float]) -> bool:
        """Check if learning has plateaued"""
        
        if len(learning_curve) < self.window_size:
            return False
            
        recent = learning_curve[-self.window_size:]
        variance = np.var(recent)
        
        if variance < self.threshold:
            self.plateau_duration += 1
            return True
        else:
            self.plateau_duration = 0
            return False


# ==================== INTEGRATED TEST SUITE ====================

class BehavioralTestSuite:
    """Complete behavioral test suite for brain-brainstem system"""
    
    def __init__(self, output_dir: str = "./behavioral_test_results"):
        self.output_dir = output_dir
        self.scenarios = [
            ObstacleNavigationScenario(),
            ExplorationLearningScenario(),
            StressResilienceScenario()
        ]
        self.analyzer = BehavioralAnalyzer()
        self.safety_verifier = SafetyVerifier()
        self.learning_tracker = LearningProgressionTracker()
        
    def run_comprehensive_test(
        self,
        brain_client,
        brainstem,
        total_cycles: int = 500
    ) -> Dict[str, Any]:
        """Run comprehensive behavioral test battery"""
        
        print("\n" + "="*60)
        print("üß™ COMPREHENSIVE BEHAVIORAL TEST SUITE")
        print("="*60)
        
        results = {
            'test_start': datetime.now().isoformat(),
            'total_cycles': total_cycles,
            'scenarios': {},
            'overall_analysis': None,
            'safety_report': None,
            'learning_analysis': None
        }
        
        cycle_count = 0
        
        # Run each scenario
        for scenario in self.scenarios:
            print(f"\nüìã Running: {scenario.name}")
            print(f"   {scenario.description}")
            
            scenario_results = self._run_scenario(
                scenario, brain_client, brainstem, cycle_count
            )
            results['scenarios'][scenario.name] = scenario_results
            cycle_count += scenario.duration_cycles
            
            # Early termination on critical safety failures
            if scenario_results.get('critical_failure'):
                print("   üö® Critical failure - terminating test")
                break
        
        # Generate comprehensive reports
        results['overall_analysis'] = self.analyzer.generate_report()
        results['safety_report'] = self.safety_verifier.generate_safety_report()
        results['learning_analysis'] = self.learning_tracker.analyze_progression()
        
        # Save results
        self._save_results(results)
        
        # Print summary
        self._print_summary(results)
        
        return results
    
    def _run_scenario(
        self,
        scenario: TestScenario,
        brain_client,
        brainstem,
        start_cycle: int
    ) -> Dict[str, Any]:
        """Run a single test scenario"""
        
        scenario_results = {
            'name': scenario.name,
            'metrics': {},
            'behavior_counts': {},
            'critical_failure': False
        }
        
        for cycle in range(scenario.duration_cycles):
            global_cycle = start_cycle + cycle
            
            # Generate sensory input for scenario
            sensors = scenario.generate_sensory_sequence(cycle)
            
            # Process through brainstem
            motor_commands = brainstem.process_cycle(sensors)
            
            # Analyze behavior
            behavior_analysis = self.analyzer.analyze_motor_pattern(
                motor_commands.get('motors', [0, 0, 0, 0])
            )
            self.analyzer.behavior_history.append(behavior_analysis)
            
            # Track behavior emergence
            if behavior_analysis.get('behavior'):
                self.analyzer.track_emergence(behavior_analysis['behavior'], global_cycle)
            
            # Verify safety
            safe = self.safety_verifier.verify_collision_avoidance(
                sensors[0], motor_commands.get('motors', []), global_cycle
            )
            
            if not safe and cycle < 10:
                # Critical early safety failure
                scenario_results['critical_failure'] = True
                
            # Track learning
            # (In real implementation, get these from telemetry)
            self.learning_tracker.track_performance(
                global_cycle,
                prediction_error=np.random.random() * 0.5,  # Mock
                exploration_score=0.5 + cycle/scenario.duration_cycles * 0.3,  # Mock
                adaptation_rate=0.3 + np.random.random() * 0.2  # Mock
            )
            
            # Progress indicator
            if cycle % 20 == 0:
                print(f"   Cycle {cycle}/{scenario.duration_cycles}")
        
        # Evaluate metrics
        for metric in scenario.metrics:
            # In real implementation, calculate actual metric values
            mock_value = np.random.uniform(*metric.expected_range)
            scenario_results['metrics'][metric.name] = metric.evaluate(mock_value)
        
        return scenario_results
    
    def _save_results(self, results: Dict[str, Any]):
        """Save test results to file"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.output_dir}/behavioral_test_{timestamp}.json"
        
        try:
            with open(filename, 'w') as f:
                # Convert non-serializable objects
                json_results = self._prepare_for_json(results)
                json.dump(json_results, f, indent=2)
            print(f"\nüìÅ Results saved to: {filename}")
        except Exception as e:
            print(f"‚ö†Ô∏è Failed to save results: {e}")
    
    def _prepare_for_json(self, obj: Any) -> Any:
        """Prepare object for JSON serialization"""
        
        if isinstance(obj, Enum):
            return obj.value
        elif isinstance(obj, dict):
            return {k: self._prepare_for_json(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._prepare_for_json(item) for item in obj]
        else:
            return obj
    
    def _print_summary(self, results: Dict[str, Any]):
        """Print test summary"""
        
        print("\n" + "="*60)
        print("üìä TEST SUMMARY")
        print("="*60)
        
        # Overall behavior analysis
        analysis = results.get('overall_analysis', {})
        print("\nüß† Behavioral Analysis:")
        for behavior, percentage in analysis.get('behavior_distribution', {}).items():
            print(f"   {behavior}: {percentage:.1f}%")
        
        print("\n‚úÖ Achievements:")
        for achievement in analysis.get('achievements', []):
            print(f"   ‚Ä¢ {achievement}")
            
        print("\n‚ö†Ô∏è Concerns:")
        for concern in analysis.get('concerns', []):
            print(f"   ‚Ä¢ {concern}")
        
        # Safety report
        safety = results.get('safety_report', {})
        print(f"\nüõ°Ô∏è Safety Score: {safety.get('safety_score', 0):.2%}")
        print(f"   Violations: {safety.get('total_violations', 0)}")
        print(f"   Successful Reflexes: {safety.get('successful_reflexes', 0)}")
        
        # Learning analysis  
        learning = results.get('learning_analysis', {})
        print(f"\nüìà Learning Progress:")
        print(f"   Improvement: {learning.get('improvement', 0):.3f}")
        print(f"   Current Performance: {learning.get('current_performance', 0):.3f}")
        
        # Final recommendation
        print(f"\nüéØ Overall Recommendation:")
        print(f"   {analysis.get('recommendation', 'No recommendation available')}")
        print(f"   {safety.get('recommendation', '')}")
        print(f"   {learning.get('recommendation', '')}")


# ==================== MAIN TEST EXECUTION ====================

if __name__ == "__main__":
    print("Behavioral Test Strategy Module")
    print("This module provides comprehensive behavioral testing for the brain-brainstem system")
    print("\nTo use this module, import it and create a BehavioralTestSuite instance:")
    print("  suite = BehavioralTestSuite()")
    print("  results = suite.run_comprehensive_test(brain_client, brainstem)")